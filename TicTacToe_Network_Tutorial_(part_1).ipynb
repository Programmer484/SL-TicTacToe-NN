{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Programmer484/SL-TicTacToe-NN/blob/main/TicTacToe_Network_Tutorial_(part_1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxRMGC575-3O"
      },
      "source": [
        "**Hey! If you're looking for a fun interactive way to get into machine learning, you're in the right place!** üòÄ\n",
        "\n",
        "Today, we'll be applying machine learning to train an AI that can play tic-tac-toe on various board sizes! For example, 3 in a row on a 3x3 board, 4 in a row on 6x6 board, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMta9EAxC9Qp"
      },
      "source": [
        "### Demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXKLt350ehye"
      },
      "source": [
        "First off, let's start off with a sneak peek at what we'll be building throughout this tutorial üëÄ Don't worry about understanding all the code for now =)\n",
        "\n",
        "Instructions:\n",
        "\n",
        "1. Run the cell called \"final code\". It contains all the functions that will be used in training and playing.\n",
        "2. Train the neural network\n",
        "3. Play against it!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7SFVIryEBzY"
      },
      "source": [
        "#### Final code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbCdU5-vDZRE"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import pickle\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import tqdm\n",
        "\n",
        "\n",
        "# region Board\n",
        "\"\"\"Board\"\"\"\n",
        "class Board():\n",
        "    def __init__(self, width, height, win_length, turn, state=None, empties=None):\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.win_length = win_length\n",
        "        self.turn = turn\n",
        "        if state == None:\n",
        "            self.state = tuple([0 for _ in range (width)] for _ in range(height))\n",
        "            self.empties = [(x, y) for y in range (height) for x in range(width)]\n",
        "        else:  # Ensures a deepcopy is created\n",
        "            self.state = tuple(map(list, state))\n",
        "            self.empties = [*empties]\n",
        "\n",
        "    def __str__(self):\n",
        "        symbols = {1: \"X\", -1: \"O\", 0: \"_\"}\n",
        "        return \"\\n\".join(str([symbols[token] for token in row]) for row in self.state)\n",
        "\n",
        "    def deepcopy(self):\n",
        "        return Board(self.width, self.height, self.win_length, self.turn, self.state, self.empties)\n",
        "\n",
        "    def out_of_bounds(self, square):\n",
        "        x, y = square\n",
        "        return (x < 0 or             # Left edge\n",
        "                y < 0 or             # Top edge\n",
        "                x >= self.width or   # Right edge\n",
        "                y >= self.height)    # Bottom edge\n",
        "\n",
        "    def outcome(self, last_move):\n",
        "        \"\"\"\n",
        "        Determines if the last move resulted in a win or draw.\n",
        "\n",
        "        The function checks for a winning line by examining four directions from the last move:\n",
        "        - Diagonal (\\)\n",
        "        - Horizontal (-)\n",
        "        - Other Diagonal (/)\n",
        "        - Vertical (|)\n",
        "\n",
        "        For each direction, it:\n",
        "        1. Counts consecutive matching symbols in one direction\n",
        "        2. Counts consecutive matching symbols in the opposite direction\n",
        "        3. Adds the counts together (including the last move position)\n",
        "        4. If total count reaches win_length, that player wins\n",
        "        \"\"\"\n",
        "        player = self.state[last_move[1]][last_move[0]]\n",
        "        directions = [(-1, -1), (-1, 0), (-1, 1),( 0, -1)]\n",
        "        for dx, dy in directions:\n",
        "            line_length = 1\n",
        "            # Check in one direction\n",
        "            x, y = last_move[0] + dx, last_move[1] + dy\n",
        "            while not self.out_of_bounds((x, y)) and self.state[y][x] == player:\n",
        "                line_length += 1\n",
        "                x += dx\n",
        "                y += dy\n",
        "                if line_length >= self.win_length:\n",
        "                    return player\n",
        "            # Check in the opposite direction\n",
        "            x, y = last_move[0] - dx, last_move[1] - dy\n",
        "            while not self.out_of_bounds((x, y)) and self.state[y][x] == player:\n",
        "                line_length += 1\n",
        "                x -= dx\n",
        "                y -= dy\n",
        "                if line_length >= self.win_length:\n",
        "                    return player\n",
        "        if len(self.empties) == 0:\n",
        "            return 0\n",
        "        return None\n",
        "\n",
        "    def make_move(self, move_coords: tuple):\n",
        "        try:\n",
        "            self.empties.remove(move_coords)\n",
        "            self.state[move_coords[1]][move_coords[0]] = self.turn\n",
        "            self.turn *= -1\n",
        "        except:\n",
        "            raise ValueError(\"Illegal move\")\n",
        "# endregion\n",
        "\n",
        "# region MCTS\n",
        "\"\"\"MCTS\"\"\"\n",
        "class MCTS:\n",
        "    class Node:\n",
        "        def __init__(self, parent, board, move):\n",
        "            self.parent = parent\n",
        "            self.children = []\n",
        "            self.visit_count = 0\n",
        "            self.total_value = 0\n",
        "            self.board = board\n",
        "            self.move = move\n",
        "\n",
        "        def is_terminal(self):\n",
        "            return self.board.outcome(self.move) != None\n",
        "\n",
        "        def is_leaf(self):\n",
        "            return self.children == []\n",
        "\n",
        "    def __init__(self, board):\n",
        "        self.root_node = self.Node(None, board, (-2,-2))\n",
        "        self.c = 1.4142\n",
        "\n",
        "    def uct(self, parent, node, player_num):\n",
        "        if node.visit_count == 0:\n",
        "            return float(\"inf\")\n",
        "        else:\n",
        "            return (player_num * node.total_value/node.visit_count) + self.c * math.sqrt(math.log(parent.visit_count) / node.visit_count)\n",
        "\n",
        "    def select(self, node):\n",
        "        if node.is_leaf():\n",
        "            return node\n",
        "        else:\n",
        "            chosen_node = max(node.children, key=lambda child: self.uct(node, child, node.board.turn))\n",
        "            return self.select(chosen_node)\n",
        "\n",
        "    def expand(self, node):\n",
        "        legal_moves = node.board.empties\n",
        "        for m in legal_moves:\n",
        "            child_board = node.board.deepcopy()\n",
        "            child_board.make_move(m)\n",
        "            child_node = self.Node(node, child_board, m)\n",
        "            node.children.append(child_node)\n",
        "\n",
        "    def evaluate(self, node, playouts):\n",
        "        outcome = node.board.outcome(node.move)\n",
        "        if outcome != None:\n",
        "            return outcome\n",
        "        else:\n",
        "            total_value = 0\n",
        "            for _ in range (playouts):\n",
        "                total_value += self.play_random_game(node.board.deepcopy())\n",
        "            return total_value / playouts\n",
        "\n",
        "    def play_random_game(self, board):\n",
        "        game_on = True\n",
        "        while game_on:\n",
        "            move = random.choice(board.empties)\n",
        "            board.make_move(move)\n",
        "            value = board.outcome(move)\n",
        "            if value != None:\n",
        "                return value\n",
        "\n",
        "    def backpropagate(self, node, evaluation):\n",
        "        node.visit_count += 1\n",
        "        node.total_value += evaluation\n",
        "        if node.parent != None:\n",
        "            self.backpropagate(node.parent, evaluation)\n",
        "\n",
        "    def search(self, iterations, playouts=20):\n",
        "        for _ in range(iterations):\n",
        "            node = self.select(self.root_node)\n",
        "            if node.visit_count == 0 or node.is_terminal():\n",
        "                node_eval = self.evaluate(node, playouts)\n",
        "                self.backpropagate(node, node_eval)\n",
        "            else:\n",
        "                self.expand(node)\n",
        "                child_node = random.choice(node.children)\n",
        "                child_node_eval = self.evaluate(child_node, playouts)\n",
        "                self.backpropagate(child_node, child_node_eval)\n",
        "        move_probs = [[0 for _ in range(self.root_node.board.width)] for _ in range(self.root_node.board.height)]\n",
        "        for child_node in self.root_node.children:\n",
        "            prob = child_node.visit_count / self.root_node.visit_count\n",
        "            move_probs[child_node.move[1]][child_node.move[0]] = prob\n",
        "        return move_probs\n",
        "\n",
        "\n",
        "def choose_move(move_probs, temperature=1):\n",
        "    \"\"\"\n",
        "    Selects a move based on the Monte Carlo Tree Search (MCTS) probabilities, adjusting for temperature to control exploration versus exploitation.\n",
        "    Parameters:\n",
        "        temperature (float): Controls the randomness of the move selection.\n",
        "            Higher temperatures (>1) make the move selection more random (exploration),\n",
        "            while lower temperatures (<1) make it more greedy (exploitation).\n",
        "            Default is 1.\n",
        "    Returns:\n",
        "        tuple: The selected move as a tuple of (x, y) coordinates.\n",
        "    \"\"\"\n",
        "    # Get all moves and their probabilities from the MCTS output\n",
        "    moves = []\n",
        "    probs = []\n",
        "    for y in range(len(move_probs)):\n",
        "        for x in range(len(move_probs[y])):\n",
        "            if move_probs[y][x] > 0:\n",
        "                moves.append((x, y))\n",
        "                # Apply temperature to sharpen/flatten distribution\n",
        "                prob = math.pow(move_probs[y][x], 1 / temperature)\n",
        "                probs.append(prob)\n",
        "    # Normalize probabilities\n",
        "    prob_sum = sum(probs)\n",
        "    probs = [p / prob_sum for p in probs]\n",
        "    # Choose move based on probability distribution\n",
        "    return random.choices(moves, weights=probs)[0]\n",
        "# endregion\n",
        "\n",
        "# region Game generation\n",
        "\"\"\"Game generation\"\"\"\n",
        "def generate_games(num_games, mcts_iterations, board_params=(3, 3, 3)):\n",
        "    training_examples = []\n",
        "    for game_num in tqdm.tqdm(range(num_games)):\n",
        "        game_board = Board(*board_params, 1)\n",
        "        while True:\n",
        "            mcts_engine = MCTS(game_board)\n",
        "            move_probs = mcts_engine.search(mcts_iterations)\n",
        "            training_examples.append(([row[:] for row in game_board.state], move_probs))\n",
        "\n",
        "            selected_move = choose_move(move_probs)\n",
        "            game_board.make_move(selected_move)\n",
        "            if game_board.outcome(selected_move) != None:\n",
        "                break\n",
        "    return training_examples\n",
        "\n",
        "\n",
        "def process_game_data(game_data):\n",
        "    processed_data = [(torch.tensor(board, dtype=torch.float).flatten(),\n",
        "                       torch.tensor(move_probs, dtype=torch.float).flatten())\n",
        "                      for board, move_probs in game_data]\n",
        "    processed_data = [(board * (-1 if (board != 0).sum().item() % 2 == 1 else 1), probs)\n",
        "                      for board, probs in processed_data]  # Odd number of pieces means -1 player's turn\n",
        "    return processed_data\n",
        "# endregion\n",
        "\n",
        "# region Network\n",
        "\"\"\"Network\"\"\"\n",
        "class TicTacToeNet(nn.Module):\n",
        "    def __init__(self, input_size=9, hidden_size=36, output_size=9):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        x = self.fc3(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x\n",
        "# endregion\n",
        "\n",
        "# region Evaluation\n",
        "def calculate_accuracy(\n",
        "    data_set,\n",
        "    net,\n",
        "    board_size=(3, 3),\n",
        "    probability_threshold=0.1\n",
        "):\n",
        "    \"\"\"\n",
        "    A prediction is considered correct if the network's highest probability move\n",
        "    is within the probability_threshold of the target's highest probability move.\n",
        "    \"\"\"\n",
        "    correct = 0\n",
        "    for board, move_probs in data_set:\n",
        "        output = net(board)\n",
        "        best_move = torch.argmax(move_probs)\n",
        "        best_moves = (move_probs >= move_probs[best_move] - probability_threshold).nonzero().flatten()\n",
        "        if torch.argmax(output) in best_moves:\n",
        "            correct += 1\n",
        "    return correct / len(data_set)\n",
        "\n",
        "\n",
        "\n",
        "class HumanPlayer():\n",
        "    def move(self, board, **kwargs):\n",
        "        while True:\n",
        "            try:\n",
        "                move = tuple(map(int, input(\"Enter move as x,y: \").split(',')))\n",
        "                return move\n",
        "            except:\n",
        "                print(\"Invalid move, try again\")\n",
        "\n",
        "\n",
        "class NetPlayer():\n",
        "    def __init__(self, net, deterministic=False):\n",
        "        self.net = net\n",
        "        self.deterministic = deterministic\n",
        "\n",
        "    def move(self, board, print_probs=False):\n",
        "        board_tensor = torch.tensor(board.state, dtype=torch.float).flatten()\n",
        "        board_tensor = board_tensor * board.turn\n",
        "        move_probs = self.net(board_tensor)\n",
        "\n",
        "        if print_probs:\n",
        "            print(\"\\nNetwork probabilities:\")\n",
        "            for y in range(board.height):\n",
        "                print([f\"{move_probs[y*board.width + x]:.3f}\" for x in range(board.width)])\n",
        "\n",
        "        for move in range(board.width * board.height):\n",
        "            if (move % board.width, move // board.height) not in board.empties:\n",
        "                move_probs[move] = 0.0\n",
        "\n",
        "        if self.deterministic:\n",
        "            best_move_idx = torch.argmax(move_probs).item()\n",
        "        else:\n",
        "            best_move_idx = torch.multinomial(move_probs, 1).item()\n",
        "        best_move = (best_move_idx % board.width, best_move_idx // board.height)\n",
        "\n",
        "        return best_move\n",
        "\n",
        "\n",
        "class RandomPlayer():\n",
        "    def move(self, board, **kwargs):\n",
        "        return random.choice(board.empties)\n",
        "\n",
        "\n",
        "class MCTSPlayer():\n",
        "    def __init__(self, iterations, deterministic=False):\n",
        "        self.deterministic = deterministic\n",
        "        self.iterations = iterations\n",
        "\n",
        "    def move(self, board, print_probs=False):\n",
        "        mcts = MCTS(board)\n",
        "        move_probs = mcts.search(self.iterations)\n",
        "        move_probs = torch.tensor(move_probs).flatten()\n",
        "\n",
        "        if print_probs:\n",
        "            print(\"\\nMCTS probabilities:\")\n",
        "            for row in move_probs:\n",
        "                print([f\"{prob:.3f}\" for prob in row])\n",
        "\n",
        "        if self.deterministic:\n",
        "            best_move_idx = torch.argmax(move_probs).item()\n",
        "        else:\n",
        "            best_move_idx = torch.multinomial(move_probs, 1).item()\n",
        "        best_move = (best_move_idx % board.width, best_move_idx // board.height)\n",
        "\n",
        "        return best_move\n",
        "\n",
        "\n",
        "def play_game(board, player_a, player_b, print_game=False):\n",
        "    outcome = None\n",
        "    illegal_move_count = 0\n",
        "    while outcome == None:\n",
        "        if print_game:\n",
        "            player = 'X' if board.turn==1 else 'O'\n",
        "            print(f\"\\n{'='*7} {player} player's turn {'='*7}\")\n",
        "            print(f\"\\nBoard:\\n{board}\")\n",
        "        player = player_a if board.turn == 1 else player_b\n",
        "        move = player.move(board, print_probs=print_game)\n",
        "        try:\n",
        "            board.make_move(move)\n",
        "        except:\n",
        "            if illegal_move_count < 3:\n",
        "                print(\"Illegal move, try again\")\n",
        "                illegal_move_count += 1\n",
        "                continue\n",
        "            else:\n",
        "                print(\"Too many illegal moves, aborting game\")\n",
        "                return None\n",
        "        outcome = board.outcome(move)\n",
        "    if print_game:\n",
        "        print(f\"\\nGame over!\")\n",
        "        print(f\"\\nFinal board:\\n{board}\")\n",
        "    return outcome\n",
        "\n",
        "\n",
        "def run_match_series(player_a, player_b, num_games, board_params=(3, 3, 3)):\n",
        "    \"\"\"\n",
        "    Run a series of games between two players, where each player gets an equal\n",
        "    opportunity to play first. The function keeps track of wins for each player across all games.\n",
        "    \"\"\"\n",
        "    # Initialize win counters for both players\n",
        "    player_a_wins = 0\n",
        "    player_b_wins = 0\n",
        "    player_list = [[player_a, player_a_wins],\n",
        "                   [player_b, player_b_wins]]\n",
        "\n",
        "    # Play specified number of games, alternating who goes first\n",
        "    for game in tqdm.tqdm(range(num_games)):\n",
        "        current_first = player_list[0][0]\n",
        "        current_second = player_list[1][0]\n",
        "        outcome = play_game(Board(*board_params, 1), current_first, current_second, print_game=False)\n",
        "\n",
        "        # Update win counts based on game outcome\n",
        "        if outcome == 1:\n",
        "            player_list[0][1] += 1    # First player won\n",
        "        elif outcome == -1:\n",
        "            player_list[1][1] += 1    # Second player won\n",
        "\n",
        "        player_list.reverse()\n",
        "\n",
        "    # Return in original order: player_a first, player_b second\n",
        "    return player_list if player_list[0][0] == player_a else player_list.reverse()\n",
        "# endregion\n",
        "\n",
        "# region Training\n",
        "def train_net(training_data, net, num_epochs=25, learning_rate=0.3):\n",
        "    optimizer = optim.SGD(net.parameters(), lr=learning_rate)\n",
        "    loss_metric = nn.MSELoss()\n",
        "\n",
        "    for epoch in tqdm.tqdm(range(num_epochs)):\n",
        "        print(f\"========= Epoch {epoch} =========\")\n",
        "        total_loss = 0\n",
        "        for board, move_probs in training_data:\n",
        "            output = net(board)\n",
        "            loss = loss_metric(output, move_probs)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Loss: {total_loss/len(training_data)}\")\n",
        "        with torch.no_grad():\n",
        "            accuracy = calculate_accuracy(training_data, net)\n",
        "            print(f\"Accuracy: {accuracy}\")\n",
        "# endregion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GydgEzvkXJNC"
      },
      "source": [
        "<a name=\"training\"></a>\n",
        "#### Train the network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKobx33-kA4b"
      },
      "source": [
        "Feel free to experiment the numbered parameters!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evoDTGWfXNAG"
      },
      "outputs": [],
      "source": [
        "training_data = generate_games(500, 200) # parameters: num_games, search_depth (roughly corresponds to quality of the training data)\n",
        "training_data = process_game_data(training_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = TicTacToeNet(9, 512, 9)\n",
        "train_net(training_data, net, num_epochs=25, learning_rate=0.5)"
      ],
      "metadata": {
        "id": "gDcnQnL8b-sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5ggMROt5KIe"
      },
      "source": [
        "#### Evaluating the network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgyUa5F65KIf"
      },
      "source": [
        "Let's evaluate the performance of our network against random moves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZXVTxsD5KIg"
      },
      "outputs": [],
      "source": [
        "net_vs_random = run_match_series(NetPlayer(net, deterministic=False), RandomPlayer(), 1000, (3, 3, 3))\n",
        "print(f\"\\nNet vs. Random: {net_vs_random}\")\n",
        "net_vs_mcts = run_match_series(NetPlayer(net, deterministic=False), MCTSPlayer(1000, deterministic=False), 20, (3, 3, 3))\n",
        "print(f\"\\nNet vs. MCTS: {net_vs_mcts}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id_EIuMwfKCM"
      },
      "source": [
        "#### Play against the network!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzKz1WPkkVrS"
      },
      "source": [
        "The outputs will be:\n",
        "\n",
        "1. The board\n",
        "2. The network's move policy as a grid.\n",
        "  * The higher the value in a square, the more the network favours placing their token in that square.\n",
        "\n",
        "* The top left square is (0, 0)\n",
        "* Input the your move as \"x-coordinate,y-coordinate\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DR19OvvhWQ_U"
      },
      "outputs": [],
      "source": [
        "play_game(Board(3, 3, 3, 1), NetPlayer(net, deterministic=True), HumanPlayer(), print_game=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_IUiEeBsvS-"
      },
      "source": [
        "<a name=\"intro\"></a>\n",
        "### Intro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMTORr-qxZp_"
      },
      "source": [
        "Before we dive in, make sure you have a basic understanding of:\n",
        "\n",
        "1. Python\n",
        "2. Neural Networks\n",
        "  - [Full explanation: 3Blue1Brown videos](https://www.3blue1brown.com/lessons/neural-networks) (~20 min/chapter)\n",
        "  - [Quick refresher article](https://ryan-leong.medium.com/the-basics-of-neural-networks-for-chess-nerds-and-anyone-interested-in-ai-e76e03124867) (~15 min read)\n",
        "\n",
        "üõë + üß† = Stop and think about the prompts! This is where real learning happens.\n",
        "\n",
        "Let's teach an AI to play tic-tac-toe! üéÆ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dor5jatsDlw"
      },
      "source": [
        "### The plan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvFG2Ov8qLdn"
      },
      "source": [
        "Here's the plan: we'll teach our neural network to play tic-tac-toe by showing it lots of game positions and their best moves! üéÆ\n",
        "\n",
        "As it learns, it'll start recognizing cool patterns - like going for the win when it sees a chance to get 3 in a row!\n",
        "\n",
        "But wait... where do we get all these positions and moves from? ü§î\n",
        "\n",
        "üõë + üß†\n",
        "\n",
        "We have two options:\n",
        "1. Find an existing database (works for 3x3 boards)\n",
        "2. **Generate our own data** (better for different board sizes!)\n",
        "\n",
        "To generate data, we'll:\n",
        "- Have an algorithm play against itself to create games\n",
        "- Run an algorithm to figure out the best moves in each position in each game\n",
        "- Pair these positions with their best moves and package it nicely for training!\n",
        "\n",
        "#### Quick Summary\n",
        "- Generate games through self-play\n",
        "- Train the network with those games\n",
        "\n",
        "Ready to roll? Let's go! üèÅ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVMG-x2DWlTz"
      },
      "source": [
        "### Generating games through self-play"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfupaCdvszqZ"
      },
      "source": [
        "Let's break down what we need to make our own game database. Be as specific as you can!\n",
        "\n",
        "üõë + üß†\n",
        "\n",
        "Here's what we need:\n",
        "1. A game engine to track moves and check for wins\n",
        "2. An algorithm to play both sides\n",
        "3. An algorithm to find the best moves for each position\n",
        "\n",
        "Let's build that game engine :D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3DFL1tkVeec"
      },
      "source": [
        "#### Game engine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apqRz2a7Wh25"
      },
      "source": [
        "Quick tips before we start coding!\n",
        "\n",
        "1. Use a proper code editor (replit/VS Code)\n",
        "   - Better debugging with breakpoints\n",
        "   - Easier to pick up where you left off\n",
        "\n",
        "2. Turn off code suggestions\n",
        "   - Makes you think harder (that's good!)\n",
        "\n",
        "3. Google is your friend, just don't fall down web surfing rabbit holes üòâ\n",
        "\n",
        "Ok back to the game engine! I've added checkpoints to help guide you"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYWDdeYIgq_c"
      },
      "source": [
        "Part 1: Create a `Board` class that:\n",
        " 1. Tracks the current state of the board using a 2D list.\n",
        " 2. Allows players to place tokens (e.g., 1 or -1) on the board using the `make_move` method.\n",
        " 3. Prevents moves in spaces that are already occupied and raises an error if attempted.\n",
        "\n",
        "Let's use 0s for empty spaces and -1s and 1s to represent the two players. Using numbers instead of strings make it easier to integrate with machine learning models later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZ_LtLlaZJHz"
      },
      "outputs": [],
      "source": [
        "class Board:\n",
        "    def __init__(self, state):\n",
        "        \"\"\"\n",
        "        Initializes the board with the given state.\n",
        "        \"\"\"\n",
        "        self.state = state\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"\n",
        "        Formats the board as a string for printing.\n",
        "        \"\"\"\n",
        "        for row in self.state:\n",
        "            print(row)\n",
        "        return \"\"\n",
        "\n",
        "    def make_move(self, move):\n",
        "        \"\"\"\n",
        "        Updates the board by placing a token in the specified location.\n",
        "        Arguments:\n",
        "        - move: A tuple (x, y) representing the position on the board.\n",
        "\n",
        "        Raises an error if the position is already occupied.\n",
        "        \"\"\"\n",
        "        pass  # Replace this with your implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8aq6g5t5KIl"
      },
      "source": [
        "Test your class by running the code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHtK0SOy5KIl"
      },
      "outputs": [],
      "source": [
        "# Initial board state\n",
        "start_state = [[-1,  0,  0],\n",
        "               [ 0,  0,  0],\n",
        "               [ 0,  0,  1]]\n",
        "\n",
        "# Instantiate the board\n",
        "board = Board(start_state)\n",
        "\n",
        "# Player 1 places a token on (1, 1)\n",
        "board.make_move((1, 1))\n",
        "print(board)\n",
        "\n",
        "# Expected outcome:\n",
        "# [[-1,  0,  0],\n",
        "#  [ 0,  1,  0],\n",
        "#  [ 0,  0,  1]]\n",
        "\n",
        "# Player 2 tries place a token on the same spot\n",
        "board.make_move((1, 1))\n",
        "\n",
        "# Expected outcome:\n",
        "# Raise an error since the position is already occupied"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFbvbRZ9gn7u"
      },
      "source": [
        "Part 2: Alternate between placing 1s and -1s depending on whose turn it is.\n",
        "\n",
        "Update your Board class and run the code below to test it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSu9Pa_iWgkh"
      },
      "outputs": [],
      "source": [
        "# Initial board state\n",
        "start_state = [[ 1, -1,  0],\n",
        "               [ 0,  0,  0],\n",
        "               [ 0,  0,  0]]\n",
        "\n",
        "# Instantiate the board\n",
        "board = Board(start_state)\n",
        "\n",
        "# Player 1 places a token on (1, 1)\n",
        "board.make_move((1, 1))\n",
        "print(board)\n",
        "\n",
        "# Expected outcome:\n",
        "# [[1, -1,  0],\n",
        "#  [0,  1,  0],\n",
        "#  [0,  0,  0]]\n",
        "\n",
        "# Player 2 places a token on (2, 2)\n",
        "board.make_move((2, 2))\n",
        "print(board)\n",
        "# Expected outcome:\n",
        "# [[1, -1,  0],\n",
        "#  [0,  1,  0],\n",
        "#  [0,  0, -1]]\n",
        "\n",
        "# Player 1 places a token on (0, 1)\n",
        "board.make_move((0, 1))\n",
        "print(board)\n",
        "# Expected outcome:\n",
        "# [[1, -1,  0],\n",
        "#  [1,  1,  0],\n",
        "#  [0,  0, -1]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck--APcTgP7Q"
      },
      "source": [
        "Part 3: Check if the game has ended and return the outcome\n",
        "\n",
        "Update your Board class and run the code below to test it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgLEgx3Yavjc"
      },
      "outputs": [],
      "source": [
        "# Define different board states to test the \"outcome\" method.\n",
        "start_state1 = [[ 1,  0, -1],\n",
        "                [ 0,  1, -1],\n",
        "                [ 0,  0,  1]]\n",
        "\n",
        "board1 = Board(start_state1)\n",
        "print(board1.outcome())  # Expected outcome: 1 (Player 1 wins)\n",
        "\n",
        "\n",
        "start_state2 = [[-1,  0,  1],\n",
        "                [-1,  1,  0],\n",
        "                [-1,  0,  0]]\n",
        "board2 = Board(start_state2)\n",
        "print(board2.outcome())  # Expected outcome: -1 (Player -1 wins)\n",
        "\n",
        "\n",
        "start_state3 = [[ 1,  1, -1],\n",
        "                [-1, -1,  1],\n",
        "                [ 1, -1,  1]]\n",
        "board3 = Board(start_state3)\n",
        "print(board3.outcome())  # Expected outcome: 0 (Draw)\n",
        "\n",
        "\n",
        "start_state4 = [[ 0,  0,  0],\n",
        "                [-1,  1,  1],\n",
        "                [ 0, -1,  0]]\n",
        "board4 = Board(start_state4)\n",
        "print(board4.outcome())  # Expected outcome: None (Game not over)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFPDcOc_pQeH"
      },
      "source": [
        "Nice work coding the game engine! üéâ\n",
        "\n",
        "I've added some extra functionality to the Board class below to make it even better:\n",
        "- Works with any board size and win length\n",
        "- Super fast copying and outcome checking\n",
        "\n",
        "Let's use this version from now on to avoid any compatability issues with the rest of the tutorial :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Y4Mvi9AgHg6"
      },
      "outputs": [],
      "source": [
        "class Board():\n",
        "    def __init__(self, width, height, win_length, turn, state=None, empties=None):\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.win_length = win_length\n",
        "        self.turn = turn\n",
        "        if state == None:\n",
        "            self.state = tuple([0 for _ in range (width)] for _ in range(height))\n",
        "            self.empties = [(x, y) for y in range (height) for x in range(width)]\n",
        "        else:  # Ensures a deepcopy is created\n",
        "            self.state = tuple(map(list, state))\n",
        "            self.empties = [*empties]\n",
        "\n",
        "    def __str__(self):\n",
        "        symbols = {1: \"X\", -1: \"O\", 0: \"_\"}\n",
        "        return \"\\n\".join(str([symbols[token] for token in row]) for row in self.state)\n",
        "\n",
        "    def deepcopy(self):\n",
        "        return Board(self.width, self.height, self.win_length, self.turn, self.state, self.empties)\n",
        "\n",
        "    def out_of_bounds(self, square):\n",
        "        x, y = square\n",
        "        return (x < 0 or             # Left edge\n",
        "                y < 0 or             # Top edge\n",
        "                x >= self.width or   # Right edge\n",
        "                y >= self.height)    # Bottom edge\n",
        "\n",
        "    def outcome(self, last_move):\n",
        "        \"\"\"\n",
        "        Determines if the last move resulted in a win or draw.\n",
        "\n",
        "        The function checks for a winning line by examining four directions from the last move:\n",
        "        - Diagonal (\\)\n",
        "        - Horizontal (-)\n",
        "        - Other Diagonal (/)\n",
        "        - Vertical (|)\n",
        "\n",
        "        For each direction, it:\n",
        "        1. Counts consecutive matching symbols in one direction\n",
        "        2. Counts consecutive matching symbols in the opposite direction\n",
        "        3. Adds the counts together (including the last move position)\n",
        "        4. If total count reaches win_length, that player wins\n",
        "        \"\"\"\n",
        "        player = self.state[last_move[1]][last_move[0]]\n",
        "        directions = [(-1, -1), (-1, 0), (-1, 1),( 0, -1)]\n",
        "        for dx, dy in directions:\n",
        "            line_length = 1\n",
        "            # Check in one direction\n",
        "            x, y = last_move[0] + dx, last_move[1] + dy\n",
        "            while not self.out_of_bounds((x, y)) and self.state[y][x] == player:\n",
        "                line_length += 1\n",
        "                x += dx\n",
        "                y += dy\n",
        "                if line_length >= self.win_length:\n",
        "                    return player\n",
        "            # Check in the opposite direction\n",
        "            x, y = last_move[0] - dx, last_move[1] - dy\n",
        "            while not self.out_of_bounds((x, y)) and self.state[y][x] == player:\n",
        "                line_length += 1\n",
        "                x -= dx\n",
        "                y -= dy\n",
        "                if line_length >= self.win_length:\n",
        "                    return player\n",
        "        if len(self.empties) == 0:\n",
        "            return 0\n",
        "        return None\n",
        "\n",
        "    def make_move(self, move_coords: tuple):\n",
        "        try:\n",
        "            self.empties.remove(move_coords)\n",
        "            self.state[move_coords[1]][move_coords[0]] = self.turn\n",
        "            self.turn *= -1\n",
        "        except:\n",
        "            raise ValueError(\"Illegal move\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwjUrYJFVque"
      },
      "source": [
        "#### Move selection algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f76NkIFEDvj-"
      },
      "source": [
        "To choose moves, we should ask ourselves: What kind of positions do we want our network to be trained on?\n",
        "\n",
        "üõë + üß†\n",
        "\n",
        "Realistic ones! That eliminates using random moves. We need something smarter.\n",
        "\n",
        "Here's a thought. What if we just use the move recommended by the best move algorithm, since we're going to run it anyways?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMAEEru4Oaf-"
      },
      "source": [
        "#### Best move algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFpKriFgOetx"
      },
      "source": [
        "There's many algorithms for finding the best moves, but one called Monte Carlo Tree Search (MCTS) stands out for our purposes. This is because it gives probabilities for each move. This allows us to pick the best moves most of the time while keeping room for some not-so-optimal variations.\n",
        "\n",
        "I wrote a comprehensive tutorial on MCTS [here](https://ryan-leong.medium.com/an-intuitive-explanation-of-how-computers-play-chess-mcts-algorithm-e327ae6bea60). Go implement it and come back when you're ready!\n",
        "\n",
        "Below is the ```MCTS``` class from the tutorial, and a  ```choose_move``` function that selects a move based on the move probabilities returned by the MCTS search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zv2O55RAvUQv"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "\n",
        "\n",
        "\"\"\"MCTS\"\"\"\n",
        "class MCTS:\n",
        "    class Node:\n",
        "        def __init__(self, parent, board, move):\n",
        "            self.parent = parent\n",
        "            self.children = []\n",
        "            self.visit_count = 0\n",
        "            self.total_value = 0\n",
        "            self.board = board\n",
        "            self.move = move\n",
        "\n",
        "        def is_terminal(self):\n",
        "            return self.board.outcome(self.move) != None\n",
        "\n",
        "        def is_leaf(self):\n",
        "            return self.children == []\n",
        "\n",
        "    def __init__(self, board):\n",
        "        self.root_node = self.Node(None, board, (-2,-2))\n",
        "        self.c = 1.4142\n",
        "\n",
        "    def uct(self, parent, node, player_num):\n",
        "        if node.visit_count == 0:\n",
        "            return float(\"inf\")\n",
        "        else:\n",
        "            return (player_num * node.total_value/node.visit_count) + self.c * math.sqrt(math.log(parent.visit_count) / node.visit_count)\n",
        "\n",
        "    def select(self, node):\n",
        "        if node.is_leaf():\n",
        "            return node\n",
        "        else:\n",
        "            chosen_node = max(node.children, key=lambda child: self.uct(node, child, node.board.turn))\n",
        "            return self.select(chosen_node)\n",
        "\n",
        "    def expand(self, node):\n",
        "        legal_moves = node.board.empties\n",
        "        for m in legal_moves:\n",
        "            child_board = node.board.deepcopy()\n",
        "            child_board.make_move(m)\n",
        "            child_node = self.Node(node, child_board, m)\n",
        "            node.children.append(child_node)\n",
        "\n",
        "    def evaluate(self, node, playouts):\n",
        "        outcome = node.board.outcome(node.move)\n",
        "        if outcome != None:\n",
        "            return outcome\n",
        "        else:\n",
        "            total_value = 0\n",
        "            for _ in range (playouts):\n",
        "                total_value += self.play_random_game(node.board.deepcopy())\n",
        "            return total_value / playouts\n",
        "\n",
        "    def play_random_game(self, board):\n",
        "        game_on = True\n",
        "        while game_on:\n",
        "            move = random.choice(board.empties)\n",
        "            board.make_move(move)\n",
        "            value = board.outcome(move)\n",
        "            if value != None:\n",
        "                return value\n",
        "\n",
        "    def backpropagate(self, node, evaluation):\n",
        "        node.visit_count += 1\n",
        "        node.total_value += evaluation\n",
        "        if node.parent != None:\n",
        "            self.backpropagate(node.parent, evaluation)\n",
        "\n",
        "    def search(self, iterations, playouts=20):\n",
        "        for _ in range(iterations):\n",
        "            node = self.select(self.root_node)\n",
        "            if node.visit_count == 0 or node.is_terminal():\n",
        "                node_eval = self.evaluate(node, playouts)\n",
        "                self.backpropagate(node, node_eval)\n",
        "            else:\n",
        "                self.expand(node)\n",
        "                child_node = random.choice(node.children)\n",
        "                child_node_eval = self.evaluate(child_node, playouts)\n",
        "                self.backpropagate(child_node, child_node_eval)\n",
        "        move_probs = [[0 for _ in range(self.root_node.board.width)] for _ in range(self.root_node.board.height)]\n",
        "        for child_node in self.root_node.children:\n",
        "            prob = child_node.visit_count / self.root_node.visit_count\n",
        "            move_probs[child_node.move[1]][child_node.move[0]] = prob\n",
        "        return move_probs\n",
        "\n",
        "\n",
        "def choose_move(move_probs, temperature=1):\n",
        "    \"\"\"\n",
        "    Selects a move based on the Monte Carlo Tree Search (MCTS) probabilities, adjusting for temperature to control exploration versus exploitation.\n",
        "    Parameters:\n",
        "        temperature (float): Controls the randomness of the move selection.\n",
        "            Higher temperatures (>1) make the move selection more random (exploration),\n",
        "            while lower temperatures (<1) make it more greedy (exploitation).\n",
        "            Default is 1.\n",
        "    Returns:\n",
        "        tuple: The selected move as a tuple of (x, y) coordinates.\n",
        "    \"\"\"\n",
        "    # Get all moves and their probabilities from the MCTS output\n",
        "    moves = []\n",
        "    probs = []\n",
        "    for y in range(len(move_probs)):\n",
        "        for x in range(len(move_probs[y])):\n",
        "            if move_probs[y][x] > 0:\n",
        "                moves.append((x, y))\n",
        "                # Apply temperature to sharpen/flatten distribution\n",
        "                prob = math.pow(move_probs[y][x], 1 / temperature)\n",
        "                probs.append(prob)\n",
        "    # Normalize probabilities\n",
        "    prob_sum = sum(probs)\n",
        "    probs = [p / prob_sum for p in probs]\n",
        "    # Choose move based on probability distribution\n",
        "    return random.choices(moves, weights=probs)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktczsh21HNmz"
      },
      "source": [
        "#### Creating the game dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihlqnxOfmGlK"
      },
      "source": [
        "Now it's time to put together everything we did earlier!\n",
        "\n",
        "We need a function that simulates multiple games and records each position along with its MCTS move probabilities in a list.\n",
        "\n",
        "Here‚Äôs an example of what the output might look like:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDmH-pvJ7nUd"
      },
      "source": [
        "```python\n",
        "[\n",
        "  # First position + move probabilities pair\n",
        "  (\n",
        "    # Position\n",
        "    [[0,  0,  0],\n",
        "     [0, -1,  0],\n",
        "     [0,  0,  0]],\n",
        "    # Move probabilities\n",
        "    [[0.25, 0.00, 0.25],\n",
        "     [0.00, 0.00, 0.00],\n",
        "     [0.25, 0.00, 0.25]]\n",
        "  ),\n",
        "  # Second position + move probabilities pair\n",
        "  (\n",
        "    # Position\n",
        "    [[ 0,  0,  1],\n",
        "     [ 0, -1, -1],\n",
        "     [ 0,  0,  0]],\n",
        "    # Move probabilities\n",
        "    [[0.00, 0.00, 0.00],\n",
        "     [1.00, 0.00, 0.00],\n",
        "     [0.00, 0.00, 0.00]]\n",
        "  )\n",
        "  # And so on...\n",
        "]\n",
        "```\n",
        "Note: The MCTS move probabilities in your implementation won‚Äôt always be as accurate as the examples shown here‚Äîthese are just for illustration.\n",
        "\n",
        "Your turn to build!üõ†Ô∏è"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzmFgqRgOQdV"
      },
      "outputs": [],
      "source": [
        "def generate_games(num_games, mcts_iterations, board_params=(3, 3, 3)):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        num_games (int): The number of games to generate and simulate.\n",
        "        mcts_iterations (int): The number of MCTS iterations to run on each position.\n",
        "        board_params (tuple): A tuple containing board dimensions and win condition.\n",
        "            - First value: Board width\n",
        "            - Second value: Board height\n",
        "            - Third value: Number of consecutive tokens needed to win\n",
        "    Returns:\n",
        "        list: A list of tuples containing the board state and move probabilities for each game.\n",
        "    \"\"\"\n",
        "    pass  # Replace this with your implementation\n",
        "\n",
        "training_data = generate_games(10, 200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjQrAsIx5KI4"
      },
      "source": [
        "Preview the training data here!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBjw1cgg5KI5"
      },
      "outputs": [],
      "source": [
        "def print_data_sample(training_data, positions_to_show):\n",
        "    print(\"\\nDataset Preview:\")\n",
        "    print(f\"Number of positions: {len(training_data)}\")\n",
        "    print(f\"\\nFirst {positions_to_show} positions:\")\n",
        "    for i, (board, probs) in enumerate(training_data[:positions_to_show]):\n",
        "        print(f\"\\nPosition {i+1}:\")\n",
        "\n",
        "        print(\"Board:\")\n",
        "        for row in board:\n",
        "            print([f\"{x:2.0f}\" for x in row])\n",
        "\n",
        "        print(\"\\nMove Probabilities:\")\n",
        "        for row in probs:\n",
        "            print([f\"{x:.3f}\" for x in row])\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "print_data_sample(training_data, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6AWA0yAXNzb"
      },
      "source": [
        "Woohoo! We can now generate games for our network to train on!\n",
        "\n",
        "Here‚Äôs a quick breakdown of my solution:\n",
        "1. Use MCTS to get a move probability grid for the current position.\n",
        "2. Pair the current position with the grid and add it to the list.\n",
        "3. Play a move using the choose_move function with the MCTS probabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDlUugBUSRQm"
      },
      "outputs": [],
      "source": [
        "# Solution\n",
        "import tqdm  # Progress bar\n",
        "\n",
        "\n",
        "def generate_games(num_games, mcts_iterations, board_params=(3, 3, 3)):\n",
        "    training_examples = []\n",
        "    for game_num in tqdm.tqdm(range(num_games)):\n",
        "        game_board = Board(*board_params, 1)\n",
        "        while True:\n",
        "            mcts_engine = MCTS(game_board)\n",
        "            move_probs = mcts_engine.search(mcts_iterations)\n",
        "            training_examples.append(([row[:] for row in game_board.state], move_probs))\n",
        "\n",
        "            selected_move = choose_move(move_probs)\n",
        "            game_board.make_move(selected_move)\n",
        "            if game_board.outcome(selected_move) != None:\n",
        "                break\n",
        "    return training_examples\n",
        "\n",
        "training_data = generate_games(10, 200)\n",
        "print_data_sample(training_data, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xALVzAqXWq0v"
      },
      "source": [
        "Now all we need is our neural network. We are almost there :D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5o5sDMNUrx6s"
      },
      "source": [
        "### Building the network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UphJ2TZly_6a"
      },
      "source": [
        "If you‚Äôre not already familiar with how neural networks work, now‚Äôs a great time to learn! [Jump to neural network resources](#intro).\n",
        "\n",
        "Good news: We don‚Äôt have to build a network from scratch‚Äî python's PyTorch library has us covered. Want to try building one yourself? I‚Äôll link resources at the end.\n",
        "\n",
        "In PyTorch, we define the layers in the ```__init__``` function and their connections in the ```forward``` function.\n",
        "\n",
        "Here‚Äôs an example of a neural network with 1 input, 2 hidden neurons, and 1 output.\n",
        "\n",
        "Think of layers as objects storing weights and biases, and neurons as the connection points between them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoic01w2327y"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmlaMQWSZ06x"
      },
      "source": [
        "This cell shows how we would use code to create the neural network above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9k-KcRks_eb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class ExampleNet(nn.Module):  # inherit from PyTorch's neural network base class\n",
        "    def __init__(self):\n",
        "        # Initialize parent class (required)\n",
        "        super().__init__()\n",
        "\n",
        "        # Define the network architecture:\n",
        "        # First layer: 1 input -> 2 hidden neurons\n",
        "        self.fc1 = nn.Linear(1, 2)\n",
        "        # Second layer: 2 hidden neurons -> 1 output\n",
        "        self.fc2 = nn.Linear(2, 1)\n",
        "\n",
        "    def forward(self, net_input):\n",
        "        # Forward pass - defines how data flows through the network\n",
        "\n",
        "        # Pass input through first layer\n",
        "        x = self.fc1(net_input)\n",
        "        print(f\"Hidden layer outputs (raw): {x}\")\n",
        "\n",
        "        # Apply ReLU activation to introduce non-linearity\n",
        "        # ReLU: if x < 0, output 0; else output x\n",
        "        x = F.relu(x)\n",
        "        print(f\"Hidden layer outputs (after ReLU): {x}\")\n",
        "\n",
        "        # Pass through final layer to get prediction\n",
        "        x = self.fc2(x)\n",
        "        print(f\"Network output: {x}\")\n",
        "\n",
        "        return x\n",
        "\n",
        "# Test the network\n",
        "net_in = torch.tensor([1.0])  # Create input tensor\n",
        "net = ExampleNet()  # Initialize network\n",
        "net_out = net(net_in)  # Run input through network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBha5sKvvhh-"
      },
      "source": [
        "These numbers and dimensions don‚Äôt mean much yet, so let‚Äôs build something cool‚Äîa network that takes a 3x3 board and outputs a 3x3 move probability grid.\n",
        "\n",
        "When picking a network size:\n",
        "  - Look up examples of similar models online.\n",
        "    - Too small? It won‚Äôt learn well. Too big? It‚Äôll overfit and train forever.\n",
        "    - The rest is trial and error until it works!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cn99Yzwgyv66"
      },
      "outputs": [],
      "source": [
        "class TicTacToeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, net_input):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGFWJjAsWixR"
      },
      "source": [
        "Here's an example network. The key thing is that the number of input and output neurons should both be 9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uo_Vv7W4bmG8"
      },
      "outputs": [],
      "source": [
        "class TicTacToeNet(nn.Module):\n",
        "    def __init__(self, input_size=9, hidden_size=36, output_size=9):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, net_input):\n",
        "        x = self.fc1(net_input)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        x = self.fc3(x)\n",
        "        net_output = torch.sigmoid(x)\n",
        "        return net_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL0r0zJUgAzc"
      },
      "source": [
        "If you tried to feed the board directly to the network, you would've gotten an error‚Äîthat's because out network only eats and poops out tensors!üí©\n",
        "\n",
        "What's a tensor?\n",
        "\n",
        "A tensor is like a list that only holds numbers. In neural networks, each tensor also has a `grad` property which tracks how much each weight and bias contributed to the final result to save computing time.\n",
        "\n",
        "In fact, weights and biases in each layer of a neural network are stored as tensors. To perform calculations, we need to convert the input into a tensor first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZD7SSEsjjDpd"
      },
      "outputs": [],
      "source": [
        "layer = nn.Linear(4, 2)\n",
        "print(layer.weight)\n",
        "print(layer.bias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnlkUJBNrT5x"
      },
      "source": [
        "Tensors can also come in any dimension. Each additional dimension is represented by another layer of nesting.\n",
        "\n",
        "```python\n",
        "# 0D Tensor (scalar)\n",
        "0\n",
        "# 1D Tensor (vector)\n",
        "[0, 0]\n",
        "# 2D Tensor (matrix)\n",
        "[[0, 0],\n",
        " [0, 0]]\n",
        "# 3D Tensor\n",
        "[\n",
        "  [[0, 0],\n",
        "   [0, 0]],\n",
        "\n",
        "  [[0, 0],\n",
        "   [0, 0]]\n",
        "]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyd7uJNk5KI-"
      },
      "source": [
        "Before using our network, we need to flatten the board since our network structure only accepts 1D tensor inputs. Luckily, PyTorch makes it easy!\n",
        "\n",
        "Also, don't forget to initialize input tensors with ```dtype=torch.float``` so the operations between the network‚Äôs weight, bias, and input tensors work properly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKa8I7_OrdWR"
      },
      "outputs": [],
      "source": [
        "board_state = [[1, 0, 0],\n",
        "               [0,-1, 0],\n",
        "               [1, 0, 0]]\n",
        "board_tensor = torch.tensor(board_state, dtype=torch.float)\n",
        "print(board_tensor)\n",
        "flattened_board_tensor = board_tensor.flatten()\n",
        "print(flattened_board_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1_Hb8i_5KI_"
      },
      "source": [
        "Let's feed our board into the network!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LkL9vtfWxa_Q"
      },
      "outputs": [],
      "source": [
        "board_state = [[1, 0, 0],\n",
        "               [0,-1, 0],\n",
        "               [1, 0, 0]]\n",
        "\n",
        "flattened_board = torch.tensor(board_state, dtype=torch.float).flatten()\n",
        "net = TicTacToeNet()\n",
        "net_out = net(flattened_board)\n",
        "print(net_out)  # Actual network output is in the form of a 1D tensor\n",
        "print(net_out.view(3, 3))  # View probabilites as a 3x3 grid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzLcdpsjpSxf"
      },
      "source": [
        "These numbers in the grid are the probabilities the untrained network has assigned to each move. They're totally random right now but it'll get better once the network starts trainingüèãÔ∏èüèãÔ∏èüèãÔ∏è\n",
        "\n",
        "Let's teach the network how to use those _weights_ üòÅ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0QOJ-6szZXD"
      },
      "source": [
        "### Training the network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyZveCrjv4AX"
      },
      "source": [
        "What do we need to train the network again? The more specific your steps, the better :)\n",
        "\n",
        "üõë + üß†\n",
        "\n",
        "Here‚Äôs what we need:  \n",
        "1. A **loss function**‚Äîthis tells us how wrong the network's predictions are compared to the best moves we expect.  \n",
        "2. **Gradient descent**‚Äîthis helps the network tweak its settings (weights and biases) to improve its predictions by reducing that loss.   \n",
        "\n",
        "Let's start with measuring *how wrong* the network is. How might we do that?\n",
        "\n",
        "üõë + üß†\n",
        "\n",
        "We‚Äôll compare its predicted move probabilities with those from our trusty MCTS (Monte Carlo Tree Search) grid. Bigger differences = bigger loss.  \n",
        "\n",
        "One simple way is to square the difference for each move. For example:  \n",
        "- If the network says a move (0, 0) has a 60% chance (0.6) and MCTS says 10% (0.1), the loss for that move is:  \n",
        "  \\((0.6 - 0.1)^2 = 0.25\\).  \n",
        "- We do this for all moves, average the results, and voila‚Äîwe have our loss function\n",
        "\n",
        "But why code all that by hand when PyTorch already has a built-in tool? It's called **MSE (Mean Squared Error) Loss**, and here‚Äôs how we use it:  \n",
        "1. Create a loss calculator: `loss_metric = nn.MSELoss()`.  \n",
        "2. Feed it the network‚Äôs predictions and the target values‚Äîit‚Äôll give you the loss.  \n",
        "\n",
        "Here's an example below:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5JmH2hd5lia"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "loss_metric = nn.MSELoss()\n",
        "prediction = torch.tensor([0.6, 0.8])\n",
        "target = torch.tensor([0.1, 0.8])\n",
        "# Loss for (0.6 - 0.1)^2 = 0.25\n",
        "# Loss for (0.8 - 0.8)^2 = 0\n",
        "# Average of the two losses = 0.125\n",
        "loss = loss_metric(prediction, target)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2YhAqP45KJB"
      },
      "source": [
        "How do we adjust the network's parameters based on the loss?\n",
        "\n",
        "üõë + üß†\n",
        "\n",
        "Calculate how small changes in the weights and biases affect the loss (i.e., the derivatives of the loss with respect to the weights and biases). If you want to refresh your knowledge of derivatives, check out 3blue1brown's calculus playlist.\n",
        "\n",
        "Otherwise, just know there's a mathematical way to see how weights and biases impact the loss. This includes which direction and magnitude we need to nudge each weight and bias by to reduce the loss!\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJmwPOs-5Pa0"
      },
      "source": [
        "How do we code this? PyTorch has us covered :)\n",
        "\n",
        "Let's go over how we'd implement 1 step of gradient descent with PyTorch:\n",
        "\n",
        "1. **Calculate the Loss:**  \n",
        "   Measure how far the network‚Äôs prediction is from the target using a loss function.\n",
        "\n",
        "2. **Compute Gradients:**  \n",
        "   Call `loss.backward()` to calculate how much and in which direction to adjust each weight and bias to reduce the loss.\n",
        "\n",
        "3. **Update Weights:**  \n",
        "   Call `optimizer.step()` to adjust the network's weights and biases based on the gradients. Think of the optimizer object like a coach that tells your neural network how to adjust each weight and bias :)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RH72pkXrsFjf"
      },
      "source": [
        "Let's break it down with a simple example!\n",
        "\n",
        "Imagine a neural network with just one neuron. I've set the weight and bias so you can easily follow the math if you'd like.\n",
        "\n",
        "In this case, the network is modeled by the equation:\n",
        "y = Wx + b\n",
        "\n",
        "```python\n",
        "# y = network output\n",
        "# W = weight\n",
        "# x = input\n",
        "# b = bias\n",
        "```\n",
        "\n",
        "For our example, we want the network to give an output of 2 when the input is 2.\n",
        "\n",
        "Visually, we're aiming for the equation of the line to pass through the point (2, 2)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AByOsPho8yq"
      },
      "outputs": [],
      "source": [
        "class SingleNeuronNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(1, 1)  # Define a fully connected layer with 1 input and 1 output\n",
        "        self.fc1.weight.data = torch.tensor([[0.5]])  # Set weight to 0.5\n",
        "        self.fc1.bias.data = torch.tensor([0.5])  # Set bias to 0.5\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.fc1(x)  # Apply the linear transformation (y = Wx + b)\n",
        "        return y  # Return the output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQMj1bvftKee"
      },
      "source": [
        "Next we create the network, loss function, optimizer, and a tensor storing the target output. The optimizer takes the network‚Äôs parameters and a learning rate as input.\n",
        "- A **small learning rate** makes slow, careful updates to the network's weights and biases.  \n",
        "- A **large learning rate** takes bigger steps but risks overshooting the goal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJAMDGWctJRv"
      },
      "outputs": [],
      "source": [
        "# Creating the network, loss metric, and optimizer objects.\n",
        "net = SingleNeuronNet()\n",
        "loss_metric = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.1)\n",
        "target = torch.tensor([2.0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBsrikdwth5N"
      },
      "source": [
        "We run an initial test on the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rk-Dx87atUeY"
      },
      "outputs": [],
      "source": [
        "prediction = net(torch.tensor([2.0]))\n",
        "print(\"Net prediction\")\n",
        "print(prediction)\n",
        "print()\n",
        "loss = loss_metric(prediction, target) # loss = (2.0 - 1.5)^2 = 0.25\n",
        "print(\"Loss\")\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd0NCk1zt6Y1"
      },
      "source": [
        "Remmeber how all weights and biases are stored in PyTorch tensors with a `grad` property, which tracks how much each weight and bias contributed to the final result?\n",
        "\n",
        "When `loss.backward()` is called `grad` (short for gradient) is updated with the derivatives of the loss with respect to each weight or bias in the tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4umlfR2sEv_"
      },
      "outputs": [],
      "source": [
        "loss.backward()\n",
        "print(\"Weight & bias gradients set after loss.backward():\")\n",
        "print()\n",
        "print(\"Weight gradient\")\n",
        "print(net.fc1.weight.grad)\n",
        "\n",
        "\n",
        "print()\n",
        "print(\"Bias gradient\")\n",
        "print(net.fc1.bias.grad)\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46nwS7eX5KJG"
      },
      "source": [
        "Here's an example to build intuition for what the gradient represents.\n",
        "\n",
        "Imagine you're hiking on a mountain path (the red curve) and trying to reach the valley (the minimum). Your position on the path is the weight, and the height is the error.\n",
        "\n",
        "At ```x = -1```, the gradient (represented by the slope of the blue line) is ```-2```, meaning the path slopes downward to the right. To reduce the error, you should move right (increase the weight). If you were at ```x = 0.5``` instead, the slope would be positive, meaning you should move left (decrease the weight).\n",
        "\n",
        "The gradient is like the network's guide, pointing it to the valley!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![derivative.png](data:image/png;base64,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))"
      ],
      "metadata": {
        "id": "rQWIUgSt80EP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gky9pYoeW-Dx"
      },
      "source": [
        "Finally, we call the step() method of our SGD optimizer, which updates the weights and biases using the gradients from loss.backward(), improving the model's accuracy with each step.\n",
        "\n",
        "As the network's weights and biases are adjusted, it starts to learns specific patterns in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwDMGm_GXAPV"
      },
      "outputs": [],
      "source": [
        "optimizer.step()\n",
        "print(\"\\nWeights & biases adjusted after optimizer.step():\")\n",
        "print(\"==== Weight ====\")\n",
        "print(net.fc1.weight.data)\n",
        "print()\n",
        "print(\"==== Bias ====\")\n",
        "print(net.fc1.bias.data)\n",
        "print()\n",
        "\n",
        "prediction = net(torch.tensor([2.0]))\n",
        "print(\"==== Net prediction ====\")\n",
        "print(prediction)\n",
        "print()\n",
        "print(\"==== Loss ====\")\n",
        "loss = loss_metric(prediction, target)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKCSd2l_mqTn"
      },
      "source": [
        "Okay, time for an exercise!\n",
        "\n",
        "Create a training loop which applies the techniques we've learned to teach our network to model the equation of a line.\n",
        "\n",
        "Run the code below to generate the training data. Each item in the list represents an (input, output) pair."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdJWNxPlkm8G",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "\n",
        "def generate_line_coordinates(slope, y_intercept, num_points):\n",
        "    \"\"\"\n",
        "    Generates a list of coordinates (x, y) that lie on a line. Skipping every other point.\n",
        "\n",
        "    Args:\n",
        "        slope: The slope of the line.\n",
        "        y_intercept: The y-intercept of the line.\n",
        "        num_points: The number of coordinate points to generate.\n",
        "\n",
        "    Returns:\n",
        "        A list of tuples, where each tuple represents a coordinate (x, y).\n",
        "    \"\"\"\n",
        "    training_coordinates = []\n",
        "    for x in range(0, num_points, 2):\n",
        "        y = slope * x + y_intercept\n",
        "        training_coordinates.append((x, y))\n",
        "    random.shuffle(training_coordinates)\n",
        "    testing_coordinates = []\n",
        "    for x in range(1, num_points, 2):\n",
        "        y = slope * x + y_intercept\n",
        "        testing_coordinates.append((x, y))\n",
        "    random.shuffle(testing_coordinates)\n",
        "\n",
        "    return training_coordinates, testing_coordinates\n",
        "\n",
        "slope = 2\n",
        "y_intercept = 1\n",
        "num_points = 30\n",
        "\n",
        "training_coordinates, testing_coordinates = generate_line_coordinates(slope, y_intercept, num_points)\n",
        "print(training_coordinates)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKSPmR33jAjw"
      },
      "source": [
        "Make sure to run ```optimizer.zero_grad()``` before ```loss.backward()``` to clear the gradients from the previous training loop iteration. Otherwise the gradients from ```loss.backward()``` will accumulate until the newtork start making adjustments that are too big (because of the large accumulated gradient)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = SingleNeuronNet()\n",
        "\n",
        "loss_metric = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.0001)  # Suggested learning rate\n",
        "\n",
        "for x, y in training_coordinates:\n",
        "    pass # Replace this with your implementation\n",
        "# Suggestion: Try printing predictions after training to see improvement!\n"
      ],
      "metadata": {
        "id": "HDN2s4YlF4tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the network below when you are ready!"
      ],
      "metadata": {
        "id": "vzBFF0HsE-j5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test network\n",
        "total_loss = 0\n",
        "for x, y in testing_coordinates:\n",
        "    target_tensor = torch.tensor([y], dtype=torch.float)\n",
        "    prediction_tensor = net(torch.tensor([x], dtype=torch.float))\n",
        "    loss = loss_metric(prediction_tensor, target_tensor)\n",
        "    total_loss += loss.item()\n",
        "print(f\"Average Loss: {total_loss/len(testing_coordinates)}\")\n",
        "\n",
        "# Print network weight and bias\n",
        "print(\"==== Weight ====\")\n",
        "print(net.fc1.weight.data)  # We expect this to be close to 2\n",
        "print()\n",
        "print(\"==== Bias ====\")\n",
        "print(net.fc1.bias.data)  # We expect this to be close to 1"
      ],
      "metadata": {
        "id": "2-uxEjSrEBUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwPMmzd6kGl7"
      },
      "source": [
        "Congrats! You just created your first full training loop!\n",
        "\n",
        "Short summary of my solution:\n",
        "\n",
        "1. Initialize the model, loss function, and optimizer.  \n",
        "2. Loop through the data to make predictions and calculate the error.  \n",
        "3. Clear old gradients.\n",
        "4. Compute new ones with `loss.backward()`.\n",
        "5. Update the model using `optimizer.step()`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXm0oH4OoqMY"
      },
      "outputs": [],
      "source": [
        "# Solution\n",
        "net = SingleNeuronNet()\n",
        "\n",
        "loss_metric = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.001)\n",
        "\n",
        "for x, y in training_coordinates:\n",
        "    target_tensor = torch.tensor([y], dtype=torch.float)\n",
        "    prediction_tensor = net(torch.tensor([x], dtype=torch.float))\n",
        "    loss = loss_metric(prediction_tensor, target_tensor)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Loss: {loss}\")\n",
        "\n",
        "    # Extra info if you are curious\n",
        "    # print(f\"Net input: {x}\")\n",
        "    # print(f\"Weight: {net.fc1.weight.data}\")\n",
        "    # print(f\"Weight gradient: {net.fc1.weight.grad}\")\n",
        "    # print(f\"Bias: {net.fc1.bias.data}\")\n",
        "    # print(f\"Bias gradient: {net.fc1.bias.grad}\")\n",
        "    # print(f\"Target output: {target_tensor}\")\n",
        "    # print(f\"Net output: {prediction_tensor}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJOYVb_qlaxq"
      },
      "source": [
        "### Building the Ultimate Tic-Tac-Toe AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pP4HrUP2mJ_7"
      },
      "source": [
        "We have everything we need to create the tic-tac-toe network now!‚ú®\n",
        "\n",
        "Copy the code above (with all our Board, MCTS, game generation, and Network classes) to your editor first.\n",
        "\n",
        "Now let's train it! You'll know it's working when the loss starts dropping. We'll get it to play actual games next ;)\n",
        "\n",
        "If you are _really_ stuck check out the \"Training\" region of the \"Final code\" section up top. To get there, click [this](#training) and scroll up.\n",
        "\n",
        "\n",
        "\n",
        "You got this ^-^"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-WCidoIsHZo"
      },
      "source": [
        "#### Previous classes & functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GH5VEAnn5KJQ"
      },
      "outputs": [],
      "source": [
        "# region Board\n",
        "\"\"\"Board\"\"\"\n",
        "class Board():\n",
        "    def __init__(self, width, height, win_length, turn, state=None, empties=None):\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.win_length = win_length\n",
        "        self.turn = turn\n",
        "        if state == None:\n",
        "            self.state = tuple([0 for _ in range (width)] for _ in range(height))\n",
        "            self.empties = [(x, y) for y in range (height) for x in range(width)]\n",
        "        else:  # Ensures a deepcopy is created\n",
        "            self.state = tuple(map(list, state))\n",
        "            self.empties = [*empties]\n",
        "\n",
        "    def __str__(self):\n",
        "        symbols = {1: \"X\", -1: \"O\", 0: \"_\"}\n",
        "        return \"\\n\".join(str([symbols[token] for token in row]) for row in self.state)\n",
        "\n",
        "    def deepcopy(self):\n",
        "        return Board(self.width, self.height, self.win_length, self.turn, self.state, self.empties)\n",
        "\n",
        "    def out_of_bounds(self, square):\n",
        "        x, y = square\n",
        "        return (x < 0 or             # Left edge\n",
        "                y < 0 or             # Top edge\n",
        "                x >= self.width or   # Right edge\n",
        "                y >= self.height)    # Bottom edge\n",
        "\n",
        "    def outcome(self, last_move):\n",
        "        player = self.state[last_move[1]][last_move[0]]\n",
        "        directions = [(-1, -1), (-1, 0), (-1, 1),\n",
        "                      ( 0, -1),          ( 0, 1),\n",
        "                      ( 1, -1), ( 1, 0), ( 1, 1)]\n",
        "        for dx, dy in directions:\n",
        "            line_length = 1\n",
        "            # Check in one direction\n",
        "            x, y = last_move[0] + dx, last_move[1] + dy\n",
        "            while not self.out_of_bounds((x, y)) and self.state[y][x] == player:\n",
        "                line_length += 1\n",
        "                x += dx\n",
        "                y += dy\n",
        "            # Check in the opposite direction\n",
        "            x, y = last_move[0] - dx, last_move[1] - dy\n",
        "            while not self.out_of_bounds((x, y)) and self.state[y][x] == player:\n",
        "                line_length += 1\n",
        "                x -= dx\n",
        "                y -= dy\n",
        "            if line_length >= self.win_length:\n",
        "                return player\n",
        "        if len(self.empties) == 0:\n",
        "            return 0\n",
        "        return None\n",
        "\n",
        "    def make_move(self, move_coords: tuple):\n",
        "        try:\n",
        "            self.empties.remove(move_coords)\n",
        "            self.state[move_coords[1]][move_coords[0]] = self.turn\n",
        "            self.turn *= -1\n",
        "        except:\n",
        "            raise ValueError(\"Illegal move\")\n",
        "# endregion\n",
        "\n",
        "# region MCTS\n",
        "\"\"\"MCTS\"\"\"\n",
        "class MCTS:\n",
        "    class Node:\n",
        "        def __init__(self, parent, board, move):\n",
        "            self.parent = parent\n",
        "            self.children = []\n",
        "            self.visit_count = 0\n",
        "            self.total_value = 0\n",
        "            self.board = board\n",
        "            self.move = move\n",
        "\n",
        "        def is_terminal(self):\n",
        "            return self.board.outcome(self.move) != None\n",
        "\n",
        "        def is_leaf(self):\n",
        "            return self.children == []\n",
        "\n",
        "    def __init__(self, board):\n",
        "        self.root_node = self.Node(None, board, (-2,-2))\n",
        "        self.c = 1.4142\n",
        "\n",
        "    def uct(self, parent, node, player_num):\n",
        "        if node.visit_count == 0:\n",
        "            return float(\"inf\")\n",
        "        else:\n",
        "            return (player_num * node.total_value/node.visit_count) + self.c * math.sqrt(math.log(parent.visit_count) / node.visit_count)\n",
        "\n",
        "    def select(self, node):\n",
        "        if node.is_leaf():\n",
        "            return node\n",
        "        else:\n",
        "            chosen_node = max(node.children, key=lambda child: self.uct(node, child, node.board.turn))\n",
        "            return self.select(chosen_node)\n",
        "\n",
        "    def expand(self, node):\n",
        "        legal_moves = node.board.empties\n",
        "        for m in legal_moves:\n",
        "            child_board = node.board.deepcopy()\n",
        "            child_board.make_move(m)\n",
        "            child_node = self.Node(node, child_board, m)\n",
        "            node.children.append(child_node)\n",
        "\n",
        "    def evaluate(self, node, playouts):\n",
        "        outcome = node.board.outcome(node.move)\n",
        "        if outcome != None:\n",
        "            return outcome\n",
        "        else:\n",
        "            total_value = 0\n",
        "            for _ in range (playouts):\n",
        "                total_value += self.play_random_game(node.board.deepcopy())\n",
        "            return total_value / playouts\n",
        "\n",
        "    def play_random_game(self, board):\n",
        "        game_on = True\n",
        "        while game_on:\n",
        "            move = random.choice(board.empties)\n",
        "            board.make_move(move)\n",
        "            value = board.outcome(move)\n",
        "            if value != None:\n",
        "                return value\n",
        "\n",
        "    def backpropagate(self, node, evaluation):\n",
        "        node.visit_count += 1\n",
        "        node.total_value += evaluation\n",
        "        if node.parent != None:\n",
        "            self.backpropagate(node.parent, evaluation)\n",
        "\n",
        "    def search(self, iterations, playouts=20):\n",
        "        for _ in range(iterations):\n",
        "            node = self.select(self.root_node)\n",
        "            if node.visit_count == 0 or node.is_terminal():\n",
        "                node_eval = self.evaluate(node, playouts)\n",
        "                self.backpropagate(node, node_eval)\n",
        "            else:\n",
        "                self.expand(node)\n",
        "                child_node = random.choice(node.children)\n",
        "                child_node_eval = self.evaluate(child_node, playouts)\n",
        "                self.backpropagate(child_node, child_node_eval)\n",
        "        move_probs = [[0 for _ in range(self.root_node.board.width)] for _ in range(self.root_node.board.height)]\n",
        "        for child_node in self.root_node.children:\n",
        "            prob = child_node.visit_count / self.root_node.visit_count\n",
        "            move_probs[child_node.move[1]][child_node.move[0]] = prob\n",
        "        return move_probs\n",
        "\n",
        "\n",
        "def choose_move(move_probs, temperature=1):\n",
        "    \"\"\"\n",
        "    Selects a move based on the Monte Carlo Tree Search (MCTS) probabilities, adjusting for temperature to control exploration versus exploitation.\n",
        "    Parameters:\n",
        "        temperature (float): Controls the randomness of the move selection.\n",
        "            Higher temperatures (>1) make the move selection more random (exploration),\n",
        "            while lower temperatures (<1) make it more greedy (exploitation).\n",
        "            Default is 1.\n",
        "    Returns:\n",
        "        tuple: The selected move as a tuple of (x, y) coordinates.\n",
        "    \"\"\"\n",
        "    # Get all moves and their probabilities from the MCTS output\n",
        "    moves = []\n",
        "    probs = []\n",
        "    for y in range(len(move_probs)):\n",
        "        for x in range(len(move_probs[y])):\n",
        "            if move_probs[y][x] > 0:\n",
        "                moves.append((x, y))\n",
        "                # Apply temperature to sharpen/flatten distribution\n",
        "                prob = math.pow(move_probs[y][x], 1 / temperature)\n",
        "                probs.append(prob)\n",
        "    # Normalize probabilities\n",
        "    prob_sum = sum(probs)\n",
        "    probs = [p / prob_sum for p in probs]\n",
        "    # Choose move based on probability distribution\n",
        "    return random.choices(moves, weights=probs)[0]\n",
        "# endregion\n",
        "\n",
        "# region Game generation\n",
        "\"\"\"Game generation\"\"\"\n",
        "def generate_games(num_games, mcts_iterations, board_params=(3, 3, 3)):\n",
        "    training_examples = []\n",
        "    for game_num in tqdm.tqdm(range(num_games)):\n",
        "        game_board = Board(*board_params, 1)\n",
        "        while True:\n",
        "            mcts_engine = MCTS(game_board)\n",
        "            move_probs = mcts_engine.search(mcts_iterations)\n",
        "            training_examples.append(([row[:] for row in game_board.state], move_probs))\n",
        "\n",
        "            selected_move = choose_move(move_probs)\n",
        "            game_board.make_move(selected_move)\n",
        "            if game_board.outcome(selected_move) != None:\n",
        "                break\n",
        "    return training_examples\n",
        "# endregion\n",
        "\n",
        "# region Network\n",
        "\"\"\"Network\"\"\"\n",
        "class TTTNet(nn.Module):\n",
        "    def __init__(self, input_size=9, hidden_size=36, output_size=9):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = torch.relu(x)\n",
        "\n",
        "        x = self.fc3(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x\n",
        "# endregion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7mgPvQJx04g"
      },
      "source": [
        "#### Network training template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcfxX7zyFHHf"
      },
      "outputs": [],
      "source": [
        "# Generate data for model training\n",
        "\n",
        "net = TicTacToeNet()\n",
        "# Training settings\n",
        "# Hint: Try the SGD optimizer with a learning rate of 0.3!\n",
        "epochs = 25\n",
        "for epoch in range(epochs):\n",
        "    pass # Go through all the training examples\n",
        "         # and update our network with each one!\n",
        "\n",
        "torch.save(net.state_dict(), 'tictactoe_net.pth')  # Save the model to a file"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Congratulations on building your own ULTIMATE Tic Tac Toe network :DDDD üéä\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dEXwmtScTGjA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UyE-8P95KJS"
      },
      "source": [
        "### Evaluating the network!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Did you notice how the loss stops dropping after a while?\n",
        "\n",
        "How do we determine the level our network reached when the loss stopped dropping? Be specific.\n",
        "\n",
        "üõë + üß†\n",
        "\n",
        "Two Ideas:\n",
        "1. Play games against known opponents (e.g., MCTS, random moves).\n",
        "2. Check how often it matches MCTS‚Äôs top moves from training data.\n",
        "\n",
        "\n",
        "Let‚Äôs start with playing games. Wanna code it yourself? Go for it! Or check out my version:\n",
        "\n",
        "How it works:\n",
        "1. Players are objects with a `move` method (input: board, output: move).\n",
        "2. The `play_game` function runs a game by calling each player‚Äôs `move` method until the game ends.\n",
        "3. The `run_match_series` function simulates multiple games and tracks wins for each player.\n",
        "\n",
        "Example after this code cell!"
      ],
      "metadata": {
        "id": "o9y0Hiv9l5KU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HumanPlayer():\n",
        "    def move(self, board, **kwargs):\n",
        "        while True:\n",
        "            try:\n",
        "                move = tuple(map(int, input(\"Enter move as x,y: \").split(',')))\n",
        "                return move\n",
        "            except:\n",
        "                print(\"Invalid move, try again\")\n",
        "\n",
        "\n",
        "class NetPlayer():\n",
        "    def __init__(self, net, deterministic=False):\n",
        "        self.net = net\n",
        "        self.deterministic = deterministic\n",
        "\n",
        "    def move(self, board, print_probs=False):\n",
        "        board_tensor = torch.tensor(board.state, dtype=torch.float).flatten()\n",
        "        board_tensor = board_tensor * board.turn\n",
        "        move_probs = self.net(board_tensor)\n",
        "\n",
        "        if print_probs:\n",
        "            print(\"\\nNetwork probabilities:\")\n",
        "            for y in range(board.height):\n",
        "                print([f\"{move_probs[y*board.width + x]:.3f}\" for x in range(board.width)])\n",
        "\n",
        "        for move in range(board.width * board.height):\n",
        "            if (move % board.width, move // board.height) not in board.empties:\n",
        "                move_probs[move] = 0.0\n",
        "\n",
        "        if self.deterministic:\n",
        "            best_move_idx = torch.argmax(move_probs).item()\n",
        "        else:\n",
        "            best_move_idx = torch.multinomial(move_probs, 1).item()\n",
        "        best_move = (best_move_idx % board.width, best_move_idx // board.height)\n",
        "\n",
        "        return best_move\n",
        "\n",
        "\n",
        "class RandomPlayer():\n",
        "    def move(self, board, **kwargs):\n",
        "        return random.choice(board.empties)\n",
        "\n",
        "\n",
        "class MCTSPlayer():\n",
        "    def __init__(self, iterations, deterministic=False):\n",
        "        self.deterministic = deterministic\n",
        "        self.iterations = iterations\n",
        "\n",
        "    def move(self, board, print_probs=False):\n",
        "        mcts = MCTS(board)\n",
        "        move_probs = mcts.search(self.iterations)\n",
        "        move_probs = torch.tensor(move_probs).flatten()\n",
        "\n",
        "        if print_probs:\n",
        "            print(\"\\nMCTS probabilities:\")\n",
        "            for row in move_probs:\n",
        "                print([f\"{prob:.3f}\" for prob in row])\n",
        "\n",
        "        if self.deterministic:\n",
        "            best_move_idx = torch.argmax(move_probs).item()\n",
        "        else:\n",
        "            best_move_idx = torch.multinomial(move_probs, 1).item()\n",
        "        best_move = (best_move_idx % board.width, best_move_idx // board.height)\n",
        "\n",
        "        return best_move\n",
        "\n",
        "\n",
        "def play_game(board, player_a, player_b, print_game=False):\n",
        "    outcome = None\n",
        "    illegal_move_count = 0\n",
        "    while outcome == None:\n",
        "        if print_game:\n",
        "            player = 'X' if board.turn==1 else 'O'\n",
        "            print(f\"\\n{'='*7} {player} player's turn {'='*7}\")\n",
        "            print(f\"\\nBoard:\\n{board}\")\n",
        "        player = player_a if board.turn == 1 else player_b\n",
        "        move = player.move(board, print_probs=print_game)\n",
        "        try:\n",
        "            board.make_move(move)\n",
        "        except:\n",
        "            if illegal_move_count < 3:\n",
        "                print(\"Illegal move, try again\")\n",
        "                illegal_move_count += 1\n",
        "                continue\n",
        "            else:\n",
        "                print(\"Too many illegal moves, aborting game\")\n",
        "                return None\n",
        "        outcome = board.outcome(move)\n",
        "    if print_game:\n",
        "        print(f\"\\nGame over!\")\n",
        "        print(f\"\\nFinal board:\\n{board}\")\n",
        "    return outcome\n",
        "\n",
        "\n",
        "def run_match_series(player_a, player_b, num_games, board_params=(3, 3, 3)):\n",
        "    \"\"\"\n",
        "    Run a series of games between two players, where each player gets an equal\n",
        "    opportunity to play first. The function keeps track of wins for each player across all games.\n",
        "    \"\"\"\n",
        "    # Initialize win counters for both players\n",
        "    player_a_wins = 0\n",
        "    player_b_wins = 0\n",
        "    player_list = [[player_a, player_a_wins],\n",
        "                   [player_b, player_b_wins]]\n",
        "\n",
        "    # Play specified number of games, alternating who goes first\n",
        "    for game in tqdm.tqdm(range(num_games)):\n",
        "        current_first = player_list[0][0]\n",
        "        current_second = player_list[1][0]\n",
        "        outcome = play_game(Board(*board_params, 1), current_first, current_second, print_game=False)\n",
        "\n",
        "        # Update win counts based on game outcome\n",
        "        if outcome == 1:\n",
        "            player_list[0][1] += 1    # First player won\n",
        "        elif outcome == -1:\n",
        "            player_list[1][1] += 1    # Second player won\n",
        "\n",
        "        player_list.reverse()\n",
        "\n",
        "    # Return in original order: player_a first, player_b second\n",
        "    return player_list if player_list[0][0] == player_a else player_list.reverse()"
      ],
      "metadata": {
        "id": "W14TsJyRJAmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's pit our net against an MCTS bot (200 iterations) and a random player!\n",
        "\n",
        "Setting ```deterministic = False``` lets the MCTS and the net pick moves based on their move probability outputs, keeping the games varied. Setting it to ```True``` means they always pick the top move, resulting in better performance. However, this results in repeating the same game when _both_ players have ```deterministic = True```"
      ],
      "metadata": {
        "id": "q0RslFF0M6kX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Gn1bnQ-5KJS"
      },
      "outputs": [],
      "source": [
        "# net = TicTacToeNet()  # Create a new net\n",
        "# net.load_state_dict(torch.load('tictactoe_net.pth'))  # Load the saved model into this net\n",
        "\n",
        "net_player = NetPlayer(net, deterministic=False)\n",
        "random_player = RandomPlayer()\n",
        "mcts_player = MCTSPlayer(200, deterministic=False)\n",
        "\n",
        "net_vs_random = run_match_series(net_player, random_player, 1000)\n",
        "print(f\"\\nNet vs. Random: {net_vs_random}\")\n",
        "\n",
        "net_vs_mcts = run_match_series(net_player, mcts_player, 1000)\n",
        "print(f\"\\nNet vs. MCTS: {net_vs_mcts}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The only catch? Running this during every single epoch could take ages, especially on a larger board.\n",
        "\n",
        "A faster method (which provides a rougher evaluation), is comparing the network's predictions to the MCTS top moves. Instead of calculating loss, we opt for a more practical metric‚Äîaccuracy\n",
        "\n",
        "Here‚Äôs how I approached it:\n",
        "A prediction counts as correct if the network‚Äôs highest-probability move shows up in the MCTS algorithm‚Äôs list of top moves.\n",
        "\n",
        "This ensures that if the MCTS algorithm ranks multiple moves as equally strong (e.g., all moves with a probability within 0.1 of the top MCTS move), the network's prediction is considered correct as long as it selects any of those top-ranked moves.\n",
        "\n",
        "We get the network's accuracy by dividing the correct number of predictions by the total number of predictions.\n",
        "\n"
      ],
      "metadata": {
        "id": "qmBHwUE5U88W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(\n",
        "    data_set,\n",
        "    net,\n",
        "    board_size=(3, 3),\n",
        "    probability_threshold=0.1\n",
        "):\n",
        "    \"\"\"\n",
        "    A prediction is considered correct if the network's highest probability move\n",
        "    is within the probability_threshold of the target's highest probability move.\n",
        "    \"\"\"\n",
        "    correct = 0\n",
        "    for board, move_probs in data_set:\n",
        "        output = net(board)\n",
        "        best_move = torch.argmax(move_probs)\n",
        "        best_moves = (move_probs >= move_probs[best_move] - probability_threshold).nonzero().flatten()\n",
        "        if torch.argmax(output) in best_moves:\n",
        "            correct += 1\n",
        "    return correct / len(data_set)\n"
      ],
      "metadata": {
        "id": "hJOnFKVFJ5b_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's an example on how to use it.\n",
        "\n",
        "You could also run it at the end of every training epoch in your training loop."
      ],
      "metadata": {
        "id": "XEjgIpWjThN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = generate_games(10, 200)\n",
        "test_data = process_game_data(test_data)  # convert board and move_probs to tensors and flatten\n",
        "accuracy = calculate_accuracy(test_data, net)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "wVf61In3cvHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wrapping up"
      ],
      "metadata": {
        "id": "wYTUVN5jf_Ja"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's it!! Congrats on getting this farüéâüéäüéâüéäüéâ\n",
        "\n",
        "You've built your own Tic-Tac-Toe AI and explored key concepts like getting appropiate training data, choosing network architecture, and evaluating models‚Äîessential skills for *any* machine learning project.\n"
      ],
      "metadata": {
        "id": "h9NhmXjjhhc9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generalizing to Other Board Sizes"
      ],
      "metadata": {
        "id": "0GQjk8RtgG5K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "At the beginning of this tutorial, I mentioned that this approach generalizes to various board sizes.\n",
        "\n",
        "However, generating games for such larger boards can take significantly longer‚Äîpotentially an hour or more! This happens because:\n",
        "1. **MCTS random playouts** take longer to finish as the board size grows.\n",
        "2. We need more **iterations of MCTS** to identify the **top moves** and generate high-quality training data.\n",
        "\n",
        "The challenges don't stop there. Even after generating data, we‚Äôll likely need a **larger network** and **longer training times** to capture the additional complexity.\n",
        "\n",
        "But don‚Äôt worry! There are a couple of ways to overcome these barriers:\n",
        "\n",
        "1. Replace random MCTS playouts with **faster neural network evaluations**.  \n",
        "2. Use a **convolutional neural network (CNN)**, which enables the network to easily recognize and apply patterns across different parts of the board.\n",
        "\n",
        "We‚Äôll cover these in *Part 2*, so stay tuned!  \n"
      ],
      "metadata": {
        "id": "6cCReREJgKSL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Next steps"
      ],
      "metadata": {
        "id": "Wexppreyfo6P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember, this approach isn‚Äôt just for Tic-Tac-Toe‚Äîit can inspire AI projects for anything that excites you, game-related or not! :)\n",
        "\n",
        "Finally, your **feedback is invaluable**, so let me know how this tutorial helped and how it could be improved [here](https://docs.google.com/forms/d/e/1FAIpQLSf1Hyd4vS6Sx6YDmOOyynrfBkKfRfckkWABxIGfP5Joj1Ik2A/viewform). Keep building =Düõ†Ô∏è"
      ],
      "metadata": {
        "id": "f22MflD6jqQ_"
      }
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}